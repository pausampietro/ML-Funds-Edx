{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Winery classification using the one-dimensional Gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Wine** data set is the running example for our discussion of the *generative approach to classification*. \n",
    "\n",
    "The data can be downloaded from the UCI repository (https://archive.ics.uci.edu/ml/datasets/wine). It contains 178 labeled data points, each corresponding to a bottle of wine:\n",
    "* The features (`x`): a 13-dimensional vector consisting of visual and chemical features for the bottle of wine\n",
    "* The label (`y`): the winery from which the bottle came (1,2,3)\n",
    "\n",
    "Before continuing, download the data set and place it in the same directory as this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load in the data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by loading the packages we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard includes\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Useful module for dealing with the Gaussian density\n",
    "from scipy.stats import norm, multivariate_normal\n",
    "# installing packages for interactive graphs\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, IntSlider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load the Wine data set. There are 178 data points, each with 13 features and a label (1,2,3).\n",
    "We will divide these into a training set of 130 points and a test set of 48 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'wine.data.txt' needs to be in the same directory\n",
    "data = np.loadtxt('wine.data.txt', delimiter=',')\n",
    "# Names of features\n",
    "featurenames = ['Alcohol', 'Malic acid', 'Ash', 'Alcalinity of ash','Magnesium', 'Total phenols', \n",
    "                'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins', 'Color intensity', 'Hue', \n",
    "                'OD280/OD315 of diluted wines', 'Proline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.000e+00, 1.423e+01, 1.710e+00, ..., 1.040e+00, 3.920e+00,\n",
       "        1.065e+03],\n",
       "       [1.000e+00, 1.320e+01, 1.780e+00, ..., 1.050e+00, 3.400e+00,\n",
       "        1.050e+03],\n",
       "       [1.000e+00, 1.316e+01, 2.360e+00, ..., 1.030e+00, 3.170e+00,\n",
       "        1.185e+03],\n",
       "       ...,\n",
       "       [3.000e+00, 1.327e+01, 4.280e+00, ..., 5.900e-01, 1.560e+00,\n",
       "        8.350e+02],\n",
       "       [3.000e+00, 1.317e+01, 2.590e+00, ..., 6.000e-01, 1.620e+00,\n",
       "        8.400e+02],\n",
       "       [3.000e+00, 1.413e+01, 4.100e+00, ..., 6.100e-01, 1.600e+00,\n",
       "        5.600e+02]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix a particular \"random\" permutation of the data, and use these to effect the training / test split.\n",
    "We get four arrays:\n",
    "* `trainx`: 130x13, the training points\n",
    "* `trainy`: 130x1, labels of the training points\n",
    "* `testx`: 48x13, the test points\n",
    "* `testy`: 48x1, labels of the test points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split 178 instances into training set (trainx, trainy) of size 130 and test set (testx, testy) of size 48\n",
    "# Also split apart data and labels\n",
    "np.random.seed(0)\n",
    "perm = np.random.permutation(178)\n",
    "trainx = data[perm[0:130],1:14]\n",
    "trainy = data[perm[0:130],0]\n",
    "testx = data[perm[130:178], 1:14]\n",
    "testy = data[perm[130:178],0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many training points there are from each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43, 54, 33)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(trainy==1), sum(trainy==2), sum(trainy==3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"magenta\">Fast exercise</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you figure out how many test points there are from each class? *Note down these three numbers: you will enter it as part of this week's programming assignment.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 17, 15)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# modify this cell\n",
    "sum(testy==1), sum(testy==2), sum(testy==3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Look at the distribution of a single feature from one of the wineries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pick just one feature: 'Alcohol'. This is the first feature, that is, number 0. Here is a *histogram* of this feature's values under class 1, along with the *Gaussian fit* to this distribution.\n",
    "\n",
    "<img src=\"histogram.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm: how can we generate a figure like this? \n",
    "\n",
    "The following function, **density_plot**, does this for any feature and label. The first line adds an interactive component that lets you choose these parameters using sliders. \n",
    "\n",
    "<font color=\"magenta\">Try it out!</font> And then, look at the code carefully to understand exactly what it is doing, line by line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46658fa78a734d40813dcbf526eb3a67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='feature', max=12), IntSlider(value=1, description='labelâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact_manual( feature=IntSlider(0,0,12), label=IntSlider(1,1,3))\n",
    "def density_plot(feature, label):\n",
    "    plt.hist(trainx[trainy==label,feature], normed=True)\n",
    "    #\n",
    "    mu = np.mean(trainx[trainy==label,feature]) # mean\n",
    "    var = np.var(trainx[trainy==label,feature]) # variance\n",
    "    std = np.sqrt(var) # standard deviation\n",
    "    #\n",
    "    x_axis = np.linspace(mu - 3*std, mu + 3*std, 1000)\n",
    "    plt.plot(x_axis, norm.pdf(x_axis,mu,std), 'r', lw=2)\n",
    "    plt.title(\"Winery \"+str(label) )\n",
    "    plt.xlabel(featurenames[feature], fontsize=14, color='red')\n",
    "    plt.ylabel('Density', fontsize=14, color='red')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"magenta\">Fast exercise</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\"> Exercise: </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the function **density_plot**, the code for plotting the Gaussian density focuses on the region within 3 standard deviations of the mean. Do you see where this happens? Why do you think we make this choice?\n",
    "\n",
    "Here's something for you to figure out: for which feature (0-12) does the distribution of (training set) values for winery 1 have the *smallest* standard deviation? Write down the answer: you will need to enter it as part of this week's programming assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.82962509e-01 6.56756786e-01 1.91767278e-01 2.45766535e+00\n",
      " 1.08840191e+01 3.43734147e-01 3.90396479e-01 5.96428889e-02\n",
      " 4.53274368e-01 1.22463376e+00 1.15433202e-01 3.55846328e-01\n",
      " 2.20103973e+02]\n",
      "The feature with smallest st. dev is 7: Nonflavanoid phenols\n"
     ]
    }
   ],
   "source": [
    "# modify this cell\n",
    "std = np.zeros(13)\n",
    "for feature in range(0,13):\n",
    "    std[feature] = np.std(trainx[trainy==1,feature])\n",
    "\n",
    "print(std)\n",
    "print(f\"The feature with smallest st. dev is {list(std).index(min(std))}: {featurenames[list(std).index(min(std))]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fit a Gaussian to each class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a function that will fit a Gaussian generative model to the three classes, restricted to just a single feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumes y takes on values 1,2,3\n",
    "def fit_generative_model(x,y,feature):\n",
    "    k = 3 # number of classes\n",
    "    mu = np.zeros(k+1) # list of means\n",
    "    var = np.zeros(k+1) # list of variances\n",
    "    pi = np.zeros(k+1) # list of class weights\n",
    "    for label in range(1,k+1):\n",
    "        indices = (y==label)\n",
    "        mu[label] = np.mean(x[indices,feature])\n",
    "        var[label] = np.var(x[indices,feature])\n",
    "        pi[label] = float(sum(indices))/float(len(y))\n",
    "    return mu, var, pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\"> Some tries with numpy **(Pau)** </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False, False,  True, False, False,  True, False, False,\n",
       "       False, False, False,  True, False, False, False,  True,  True,\n",
       "       False,  True, False,  True,  True, False, False, False, False,\n",
       "       False, False, False,  True,  True, False,  True,  True,  True,\n",
       "       False, False, False, False,  True,  True, False, False, False,\n",
       "        True, False, False, False,  True, False, False,  True, False,\n",
       "        True, False, False, False, False, False, False,  True, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "        True,  True, False, False, False, False, False, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "        True,  True, False,  True, False,  True, False,  True,  True,\n",
       "       False,  True, False, False,  True, False, False,  True, False,\n",
       "       False, False, False,  True, False, False,  True,  True, False,\n",
       "       False,  True,  True, False, False,  True,  True,  True, False,\n",
       "       False,  True, False, False])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainy==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13.74, 13.56, 14.06, 14.2 , 13.76, 14.19, 13.83, 13.05, 13.24,\n",
       "       13.39, 14.22, 14.21, 14.83, 13.05, 13.5 , 13.73, 13.64, 14.3 ,\n",
       "       13.56, 13.71, 13.3 , 13.16, 13.24, 14.1 , 13.05, 13.94, 14.1 ,\n",
       "       14.75, 12.85, 14.06, 13.63, 13.82, 14.37, 14.39, 13.75, 14.38,\n",
       "       14.23, 14.38, 14.12, 13.48, 13.29, 13.41, 13.2 ])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainx[trainy==1, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call this function on the feature 'alcohol'. What are the class weights?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.33076923 0.41538462 0.25384615]\n"
     ]
    }
   ],
   "source": [
    "feature = 0 # 'alcohol'\n",
    "mu, var, pi = fit_generative_model(trainx, trainy, feature)\n",
    "print(pi[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, display the Gaussian distribution for each of the three classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb3a482f112847d3907ddc7e20bd6463",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='feature', max=12), Button(description='Run Interact', stâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact_manual( feature=IntSlider(0,0,12) )\n",
    "def show_densities(feature):\n",
    "    mu, var, pi = fit_generative_model(trainx, trainy, feature)\n",
    "    colors = ['r', 'k', 'g']\n",
    "    for label in range(1,4):\n",
    "        m = mu[label]\n",
    "        s = np.sqrt(var[label])\n",
    "        x_axis = np.linspace(m - 3*s, m+3*s, 1000)\n",
    "        plt.plot(x_axis, norm.pdf(x_axis,m,s), colors[label-1], label=\"class \" + str(label))\n",
    "    plt.xlabel(featurenames[feature], fontsize=14, color='red')\n",
    "    plt.ylabel('Density', fontsize=14, color='red')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"magenta\">Fast exercise</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the widget above to look at the three class densities for each of the 13 features. Here are some questions for you:\n",
    "* For which feature (0-12) do the densities for classes 1 and 3 *overlap* the most?\n",
    "* For which feature (0-12) is class 3 the most spread out relative to the other two classes?\n",
    "* For which feature (0-12) do the three classes seem the most *separated* (this is somewhat subjective at present)?\n",
    "\n",
    "*Write down the answers to these questions: you will enter them as part of this week's assignment.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\"> **Measuring Overlap (Pau)** between 3 Classes (selected feature) </font>: **to be improved**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "539ade6f31134253ac8938fb0371a210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='feature', max=12), Button(description='Run Interact', stâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact_manual( feature=IntSlider(0,0,12) )\n",
    "def show_densities(feature):\n",
    "    mu, var, pi = fit_generative_model(trainx, trainy, feature)\n",
    "    colors = ['r', 'k', 'g']\n",
    "    for label in range(1,3):\n",
    "        m = mu[label]\n",
    "        s = np.sqrt(var[label])\n",
    "        x_axis = np.linspace(m - 3*s, m+3*s, 1000)\n",
    "        plt.plot(x_axis, norm.pdf(x_axis,m,s), colors[label-1], label=\"class \" + str(label))\n",
    "    plt.xlabel(featurenames[feature], fontsize=14, color='red')\n",
    "    plt.ylabel('Density', fontsize=14, color='red')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find the intersection points between two gaussian distribution\n",
    "def solve(m1,m2,std1,std2):\n",
    "  a = 1/(2*std1**2) - 1/(2*std2**2)\n",
    "  b = m2/(std2**2) - m1/(std1**2)\n",
    "  c = m1**2 /(2*std1**2) - m2**2 / (2*std2**2) - np.log(std2/std1)\n",
    "  return np.roots([a,b,c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate \"overlap\" among 2 gaussian distributions\n",
    "def overlap_ratio(m1,m2,std1,std2):\n",
    "    # Calculating intersection points for 2 distributions\n",
    "    result=solve(m1,m2,std1,std2)\n",
    "    # Calculating distance from mean to int_point for each gaussian dist.\n",
    "    overlap = 0\n",
    "    for int_point in result:\n",
    "        distance_1 = abs(int_point - m1)/std1\n",
    "        distance_2 = abs(int_point - m2)/std2\n",
    "        overlap += distance_1 + distance_2\n",
    "    return overlap\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da8455127455473cae0ab7354d25c3f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='feature', max=12), Button(description='Run Interact', stâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#function to add the overlap_ratio for every pair of classes (3 in total)\n",
    "@interact_manual( feature=IntSlider(0,0,12) )\n",
    "def global_overlap_feature(feature):\n",
    "    mu, var, pi = fit_generative_model(trainx, trainy, feature)\n",
    "    olap_value = 0\n",
    "    olap_value += overlap_ratio(mu[1],mu[2],np.sqrt(var[1]),np.sqrt(var[2]))\n",
    "    olap_value += overlap_ratio(mu[1],mu[3],np.sqrt(var[1]),np.sqrt(var[3]))\n",
    "    olap_value += overlap_ratio(mu[2],mu[3],np.sqrt(var[2]),np.sqrt(var[3]))\n",
    "    return olap_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Predict labels for the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How well can we predict the class (1,2,3) based just on one feature? The code below lets us find this out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error using feature Ash: 29/48\n"
     ]
    }
   ],
   "source": [
    "@interact( feature=IntSlider(0,0,12) )\n",
    "def test_model(feature):\n",
    "    mu, var, pi = fit_generative_model(trainx, trainy, feature)\n",
    "\n",
    "    k = 3 # Labels 1,2,...,k\n",
    "    n_test = len(testy) # Number of test points\n",
    "    score = np.zeros((n_test,k+1))\n",
    "    for i in range(0,n_test):\n",
    "        for label in range(1,k+1):\n",
    "            score[i,label] = np.log(pi[label]) + \\\n",
    "            norm.logpdf(testx[i,feature], mu[label], np.sqrt(var[label]))\n",
    "    predictions = np.argmax(score[:,1:4], axis=1) + 1\n",
    "    # Finally, tally up score\n",
    "    errors = np.sum(predictions != testy)\n",
    "    print \"Test error using feature \" + featurenames[feature] + \": \" + str(errors) + \"/\" + str(n_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"magenta\">One last exercise</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we are looking at classifiers that use just one out of a possible 13 features. Choosing a subset of features is called **feature selection**. In general, this is something we would need to do based solely on the *training set*--that is, without peeking at the *test set*.\n",
    "\n",
    "For the wine data, compute the training error and test error associated with each choice of feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on your findings, answer the following questions:\n",
    "* Which three features have the lowest training error? List them in order (best first).\n",
    "* Which three features have the lowest test error? List them in order (best first).\n",
    "\n",
    "*Note down your answers: you will enter them later, as part of this week's programming assignment*."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
